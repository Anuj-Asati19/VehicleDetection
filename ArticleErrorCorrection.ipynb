{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6623a222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import eng_to_ipa as ipa\n",
    "import spacy\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.chunk import tree2conlltags\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4fb76a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "NER = spacy.load(\"en_core_web_sm\", disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "858e3ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "countable_nouns = pd.read_csv('countable_nouns.csv')\n",
    "uncountable_nouns = pd.read_csv('uncountable_nouns.csv')\n",
    "countable = countable_nouns['countable_nouns'].tolist()\n",
    "uncountable = uncountable_nouns['uncountable_nouns'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2b4adf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for detecting vowel sound using phonetics\n",
    "def vowel_sound_check(string):\n",
    "    vowels = ['ə', 'i', 'aɪ', 'oʊ', 'ɔ', 'ɪ','æ','ɛ','ʊ','u','ɑ','aɪ','aʊ','a']\n",
    "    str_ipa = ipa.convert(string)\n",
    "    if str_ipa.startswith(\"ˈ\") or str_ipa.startswith(\"ˌ\"):\n",
    "        if str_ipa[1] in vowels or str_ipa[1:3] in vowels:\n",
    "            return 1\n",
    "    elif str_ipa[0] in vowels or str_ipa[0:2] in vowels:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a955c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adjective_exceptions = ['Whole','whole','first','First','Same','same','few','Few','Little','little','all','All','Both','both','Heavy','heavy','Such','such','Big','big']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "d8c768e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Article_Error_Correction(text):\n",
    "    \n",
    "    output = ''\n",
    "    \n",
    "    raw_words= word_tokenize(text)\n",
    "    iob = pos_tag(raw_words)\n",
    "    \n",
    "    #print('iob1->',iob)\n",
    "    \n",
    "    \n",
    "    #Aritcle Omission Correction\n",
    "    seen = list()\n",
    "    for i in range(len(iob)):\n",
    "        seen.append(iob[i][0])\n",
    "        \n",
    "    to_re_tag=''\n",
    "    \n",
    "    for i in range(len(iob)):\n",
    "    #Removing Extra Article from sentence\n",
    "        if i+1<len(iob) and iob[i][0] in ['The','the','A','a','An','an'] and iob[i+1][1] not in ['NN','NNP','JJ','JJR','JJS','RB','RBR']:\n",
    "            seen[i] = ''\n",
    "    for i in range(len(seen)):\n",
    "        if i+1<len(seen) and (seen[i+1] not in ['.',',','?','!',';',\"'\",':','(',')','[',']','/'] and seen[i+1].startswith(\"'\")==False) and seen[i]!='':\n",
    "            to_re_tag+=seen[i]+' '\n",
    "        else:\n",
    "            to_re_tag+=seen[i]\n",
    "    \n",
    "    #POS tagging after removal of extra article\n",
    "    raw_words= word_tokenize(to_re_tag)\n",
    "    tags = pos_tag(raw_words)\n",
    "    \n",
    "    #Chunking\n",
    "    res_chunk = ne_chunk(tags)\n",
    "    iob = tree2conlltags(res_chunk)\n",
    "    iob = list([x[:len(x)-1] for x in iob])\n",
    "    \n",
    "    #Applying NER (NLTK and Spacy)\n",
    "    NER_text= NER(to_re_tag)\n",
    "    NER_tags = list()\n",
    "    for item in iob:\n",
    "        item=list(item)\n",
    "        for w in NER_text.ents:\n",
    "            if w.text in item:\n",
    "                item.append(w.label_)\n",
    "        item=tuple(item)\n",
    "        NER_tags.append(item)\n",
    "    iob = NER_tags\n",
    "    \n",
    "    #print('iob2->',iob)\n",
    "    \n",
    "    \n",
    "    seen = list()\n",
    "    for i in range(len(iob)):\n",
    "        seen.append(iob[i][0])\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Main Loop\n",
    "    for i in range(len(iob)):\n",
    "        \n",
    "        \n",
    "        \n",
    "        #1. FOR NOUNS\n",
    "        #1.1 if previous pos tag is IN - no article used before noun\n",
    "        if iob[i][1]=='NNP' and iob[i-1][1] not in ['JJR','JJS','RBR'] and iob[i-1][0] not in ['The','the']:\n",
    "            if i+1<len(iob):\n",
    "                if iob[i+1][1] not in ['POS','VBD','VBZ'] and iob[i-1][1] not in ['NNP','IN'] :\n",
    "                    seen[i] = 'the '+iob[i][0]\n",
    "                    if iob[i-1][0] in ['A','a','An','an']: \n",
    "                        eliminate_prev(i,seen)\n",
    "                        \n",
    "                elif iob[i-1][1] == 'IN' and iob[i+1][1] in ['NN','NNPS']:\n",
    "                    seen[i] = 'the '+iob[i][0]\n",
    "                    if iob[i-1][0] in ['A','a','An','an']: \n",
    "                        eliminate_prev(i,seen)\n",
    "                        \n",
    "            elif i+2<len(iob) and iob[i+1] in ['IN'] and iob[i+2] in ['NNP']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                        \n",
    "        #1.3 NER - no ->\n",
    "        #1.3.1 singular & countable noun ->\n",
    "        elif iob[i][1] =='NN' and iob[i][0] in countable:\n",
    "            if vowel_sound_check(iob[i][0]) and iob[i-1][0] not in ['An','an']:\n",
    "                seen[i] = 'an '+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','The','the']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            #POS of previous token is IN (of,in) or noun is used after WP or WRB(What's,Where's) -> the\n",
    "            elif iob[i-1][1] in ['IN'] or (iob[i-1][1]=='POS' and iob[i-2][1] in ['WP','WRB']) and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            elif i+2<len(iob) and iob[i+1][1] in ['IN'] and iob[i+2][1] in ['NNP'] and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            elif i+1<len(iob) and iob[i-1][1] in ['VBP','VBG'] and iob[i+1][1] in ['IN'] and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            elif i+1<len(iob) and iob[i+1][1] in ['PRP'] and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            #When the POS of previous token is not in following list -> a\n",
    "            elif iob[i-1][1] not in ['DT','JJ','JJR','JJS','PRP','PRP$','NN','NNP'] and iob[i-2][1] not in ['RB','RBR'] and iob[i-1][0] not in ['A','a']:\n",
    "                seen[i] = 'a '+iob[i][0]\n",
    "                if iob[i-1][0] in ['The','the','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "            else:\n",
    "                #print('(no article is ok(singular and countable)) ->'+iob[i][0] )\n",
    "                pass\n",
    "                \n",
    "        #1.3.2 plural or uncountable\n",
    "        elif iob[i][1]=='NNS' or iob[i][0].lower() in uncountable:\n",
    "            if iob[i][0] in ['east','west','north','south','north-east','north-west','south-west','south-east'] and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            elif iob[i-1][1] == 'IN' and iob[i-2][1] in ['JJS'] and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            elif iob[i][0] in countable and iob[i][1] not in ['VBG','VBN','VBZ','VBD'] and iob[i-1][0] not in ['A','a']:\n",
    "                seen[i] = 'a '+iob[i][0]\n",
    "                if iob[i-1][0] in ['The','the','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "            else:\n",
    "                #print('(no article is ok (plural or uncountable)) ->'+iob[i][0])\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #ORDINAL NUMBERS (RB,JJ,NN)\n",
    "        flag=0\n",
    "        if 2<len(iob[i]):\n",
    "            if i+1<len(iob) and iob[i][2]=='ORDINAL' and iob[i-1][1] not in ['PRP'] and iob[i+1][1] not in ['.'] and iob[i-1][0] not in ['the','The']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                flag=1\n",
    "            elif iob[i-1][0] == 'the':\n",
    "                eliminate_prev(i,seen)\n",
    "            if flag==1:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "        #2.FOR ADJECTIVES\n",
    "        #2.1 Before superlative degree of adjective -> the\n",
    "        if iob[i][1]=='JJS' and iob[i-1][1] not in ['DT']:\n",
    "            seen[i] = \"the \"+iob[i][0]\n",
    "            if iob[i-1][0] in ['A','a','An','an']: \n",
    "                eliminate_prev(i,seen)\n",
    "\n",
    "        #2.2 Before comparative degree of adjective - next pos token is IN(Eg. of) -> the\n",
    "        elif iob[i][1] == 'JJR':\n",
    "            if i+1<len(iob) and iob[i+1][1] in ['PRP'] and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            elif i+1<len(iob) and iob[i+1][0] in ['of'] and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            elif iob[i-1][1] == 'VBZ':\n",
    "                if i+1<len(iob) and iob[i+1][1] == 'NNP':\n",
    "                    seen[i] = \"a \"+iob[i][0]\n",
    "                    if iob[i-1][0] in ['The','the','An','an']: \n",
    "                        eliminate_prev(i,seen)\n",
    "            else:\n",
    "                #print(\"no article is ok(comparitive)\")\n",
    "                pass\n",
    "\n",
    "        \n",
    "\n",
    "        #2.3. Different format for use of article with adjective( 'DT JJ Noun','DT JJ Verb','NNP DT JJ', Exceptions)\n",
    "        elif iob[i][1]=='JJ':\n",
    "            if vowel_sound_check(iob[i][0]) and iob[i-1][0] not in ['An','an']: \n",
    "                    seen[i] = \"an \"+iob[i][0]\n",
    "                    if iob[i-1][0] in ['A','a','The','the']: \n",
    "                        eliminate_prev(i,seen)\n",
    "                        \n",
    "            elif i+1<len(iob) and iob[i+1][1] in ['NNP'] and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "            elif i+1<len(iob) and iob[i+1][1] in ['NN','VB']:\n",
    "                if i+1<len(iob) and iob[i+1][1]=='VB' and iob[i-1][0] not in ['The','the']:\n",
    "                    seen[i] = 'the '+iob[i][0]\n",
    "                    if iob[i-1][0] in ['A','a','An','an']: \n",
    "                        eliminate_prev(i,seen)\n",
    "                elif iob[i-2][1] in ['RB'] and iob[i-1][0] in 'a':\n",
    "                    eliminate_prev(i,seen)\n",
    "                        \n",
    "                elif iob[i-1][1] not in ['RB'] and iob[i-1][0] not in ['A','a'] and seen[i-1].endswith('a')==False and iob[i][0] not in Adjective_exceptions:\n",
    "                    seen[i] = 'a '+iob[i][0]\n",
    "                    if iob[i-1][0] in ['The','the','An','an']: \n",
    "                        eliminate_prev(i,seen)\n",
    "                    \n",
    "            elif iob[i-1][1] in ['NNP'] and iob[i-1][0] not in ['The','the']:\n",
    "                    seen[i] = \"the \"+iob[i][0]\n",
    "                    if iob[i-1][0] in ['A','a','An','an']: \n",
    "                        eliminate_prev(i,seen)\n",
    "            \n",
    "            elif iob[i][0] in ['whole','same'] and iob[i-1][0] not in ['The','the']:\n",
    "                seen[i] = \"the \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['A','a','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "\n",
    "            elif iob[i][0] in ['few','little'] and iob[i-1][0] not in ['A','a']:\n",
    "                seen[i] = \"a \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['An','an','The','the']: \n",
    "                    eliminate_prev(i,seen)\n",
    "\n",
    "            elif iob[i][0] in ['all','both'] and iob[i-1][0] not in ['The','the']:\n",
    "                print(1)\n",
    "                seen[i] = iob[i][0]+\" the\"\n",
    "                #eliminate next case \n",
    "                if i+1<len(iob) and iob[i+1][0] in ['A','a','An','an']: \n",
    "                    eliminate_next(i)\n",
    "\n",
    "            elif i+1<len(iob) and iob[i][0] in ['heavy','big','such'] and iob[i-1][1] not in ['RB'] and iob[i+1][0] not in ['A','a']:\n",
    "                seen[i] = iob[i][0]+\" a\"\n",
    "                #eliminate next case \n",
    "                if i+1<len(iob) and iob[i+1][0] in ['The','the','An','an']: \n",
    "                    eliminate_next(i)\n",
    "            \n",
    "            elif iob[i-1][0] in ['The','the','A','a','An','an']:\n",
    "                eliminate_prev(i,seen)\n",
    "\n",
    "\n",
    "        #4. Article before adverb\n",
    "        #4.1 for the format DT RB JJ -> a    and   if sentence starts with an adverb -> no article\n",
    "        elif iob[i][1] == 'RB' and iob[i][0] not in ['as','not']:\n",
    "            if i+1<len(iob) and iob[i+1][1] in ['JJ','RB'] and i>0:\n",
    "                if i+2<len(iob) and iob[i+2][1] not in ['.'] and iob[i-1][0] not in ['A','a']:\n",
    "                    seen[i] = \"a \"+iob[i][0]\n",
    "                    if iob[i-1][0] in ['The','the','An','an']: \n",
    "                        eliminate_prev(i,seen)\n",
    "                elif i+2<len(iob) and iob[i+2][1] in ['.'] and iob[i-1][0] in ['A','a']:\n",
    "                    eliminate_prev(i,seen)\n",
    "                \n",
    "            elif i+2<len(iob) and iob[i+1][1] in ['VBG'] and iob[i+2][1] in ['NN'] and iob[i-1][0] not in ['A','a']:\n",
    "                seen[i] = \"a \"+iob[i][0]\n",
    "                if iob[i-1][0] in ['The','the','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "            \n",
    "\n",
    "        elif iob[i][1] == 'RBR' and iob[i-1][1] =='VBZ':\n",
    "            if i+1<len(iob) and iob[i+1][1] in ['NN','NNP']:\n",
    "                seen[i] = 'a '+iob[i][0]\n",
    "                if iob[i-1][0] in ['The','the','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                    \n",
    "                    \n",
    "        #For Verbs\n",
    "        elif i+1<len(iob) and iob[i][1] in ['VBG'] and iob[i+1][1] in ['PRP'] and iob[i][0] not in ['The','the']:\n",
    "            seen[i]=\"the \"+iob[i][0]\n",
    "            if iob[i-1][0] in ['A','a','An','an']: \n",
    "                eliminate_prev(i,seen)\n",
    "        \n",
    "        elif i+1<len(iob) and iob[i][1] in ['VBG'] and iob[i+1][1] in ['NN']:\n",
    "            if iob[i-1][0] not in ['a','A'] and iob[i][0] in countable and iob[i-1][1] not in ['IN']:\n",
    "                seen[i]='a '+iob[i][0]\n",
    "                if iob[i-1][0] in ['The','the','An','an']: \n",
    "                    eliminate_prev(i,seen)\n",
    "                \n",
    "        elif i+1<len(iob) and iob[i][1] in ['VBN'] and iob[i-1][1] in ['VBP'] and (iob[i-2][1] not in ['PRP'] or iob[i][0] in countable) and iob[i+1][1] in ['.'] and iob[i-1][0] not in ['a','A']:\n",
    "            seen[i] = 'a '+iob[i][0]\n",
    "            if iob[i-1][0] in ['The','the','An','an']: \n",
    "                eliminate_prev(i,seen)\n",
    "                \n",
    "        #print(seen)\n",
    "    \n",
    "    for i in range(len(seen)):\n",
    "        if i+1<len(seen) and (seen[i+1] not in ['.',',','?','!',';',\"'\",':','(',')','[',']','/'] and seen[i+1].startswith(\"'\")==False) and seen[i]!='' and i<len(iob) and \"'\" not in iob[i+1][0]:\n",
    "            output+=seen[i]+' '\n",
    "        else:\n",
    "            output+=seen[i]\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "31962e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_prev(i,seen):\n",
    "    for x in range(i):\n",
    "        if x == i-1:\n",
    "            seen[x]=''\n",
    "                    \n",
    "def eliminate_next(i,seen):        \n",
    "    for x in range(i):\n",
    "        if x== i+1:\n",
    "            seen[x]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "09dfa5c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is good boy.\n",
      "He is a good boy.\n"
     ]
    }
   ],
   "source": [
    "#For Correction of sentence only.\n",
    "inp = input()\n",
    "output = Article_Error_Correction(inp)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "2261f173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Total Score: 60 out of 64\n",
      "Accuracy =  93.75\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_input = test_df['Incorrect']\n",
    "test_correct = test_df['Correct']\n",
    "score = list()\n",
    "for item,check in zip(test_input,test_correct):\n",
    "    output = Article_Error_Correction(item)\n",
    "    if output.lower()==check.lower():\n",
    "        score.append(1)\n",
    "    else:\n",
    "        score.append(0)\n",
    "print(score)\n",
    "test_df[\"score\"] = score\n",
    "accuracy = (sum(score)/len(test_input))*100\n",
    "print(\"Total Score: \"+str(sum(score))+\" out of \"+str(len(test_input)))\n",
    "print(\"Accuracy = \",accuracy)\n",
    "test_df.to_csv('test_updated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "184fdb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Paragarph: \n",
      "Ram is very nice guy. \n",
      "\n",
      "He always helps everyone. \n",
      "\n",
      "He has the enthusiastic personality. \n",
      "\n",
      "He wants to pursue his higher studies in United States of America \n",
      "\n",
      "Output Paragraph: \n",
      "Ram is a very nice guy. \n",
      "\n",
      "He always helps everyone. \n",
      "\n",
      "He has an enthusiastic personality. \n",
      "\n",
      "He wants to pursue his higher studies in the United States of America \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For Correction of paragraphs.\n",
    "para = '''Ram is very nice guy. He always helps everyone. He has the enthusiastic personality. He wants to pursue his higher studies in United States of America'''\n",
    "\n",
    "sentence_tokens = nltk.sent_tokenize(para)\n",
    "print(\"Original Paragarph: \")\n",
    "for t in sentence_tokens:\n",
    "    print (t, \"\\n\")\n",
    "    \n",
    "print(\"Output Paragraph: \")    \n",
    "for t in sentence_tokens:   \n",
    "    output=Article_Error_Correction(t)\n",
    "    print(output,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b6c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd9d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
